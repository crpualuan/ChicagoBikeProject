{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73eaf1dd",
   "metadata": {},
   "source": [
    "# Milestone 1 - Chicago, U.S. bikesharing\n",
    "\n",
    "`Source`: \n",
    "https://data.cityofchicago.org/Transportation/Divvy-Trips/fg6s-gzvg/about_data \n",
    "\n",
    "`Mobility domain`:\n",
    "https://data.cityofchicago.org/\n",
    "\n",
    "`Github repository`:\n",
    "https://github.com/kbui-03/ChicagoBikeProject\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf681f4",
   "metadata": {},
   "source": [
    "# Target feature of the model: `TRIP DURATION` \n",
    "\n",
    "By predicting the duration of each trip, we can:\n",
    "+ Optimise charging times of electric bikes\n",
    "+ Present customers with an estimated payment recommendation\n",
    "+ Reduce bike shortages in rush hour\n",
    "+ Provide the City of Chicago with data, which could be used to improve public transportation, healthcare, or public outreach  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e291c3c7",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "Since the dataset given has a total of roughly **21 million rows**, we need to reduce the size of the data before downloading. In order to do that, we used the provided query function to filter the rows: \n",
    "\n",
    "`TRIP_ID` is greater than or equal to 22,000,000 AND\n",
    "\n",
    "`TRIP_ID` is less than or equal to 22,200,000\n",
    "\n",
    "This left us with about roughly 170.000 unique bike rides to work with, in the time frame of March 2019. We hypothesise that March is a good general representative of the whole year for a model to learn from, since:\n",
    "+ It represents the switch from cold winter months to warmer summer/spring weather, the model therefore might learn to account for these temperature changes \n",
    "+ In the same vein, the amount of precipitation/snow also represents a switch from rainy/snowy winter to sunny summer. The model should, in theory, learn these patterns \n",
    "\n",
    "**Source**: https://www.ncei.noaa.gov/access/services/data/v1?dataset=normals-monthly-1991-2020&startDate=0001-01-01&endDate=9996-12-31&stations=USC00111577&format=pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654bedf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "bike_set = pd.read_csv(\"Divvy_Trips_Chicago.csv\", sep=\",\")\n",
    "bike_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213fc737",
   "metadata": {},
   "source": [
    "# Cleaning the dataset\n",
    "**Row-wise deletion**\n",
    "\n",
    "We can observe that there are rows missing `TO LATITUDE`, `TO LONGITUDE`, `TO LOCATION`, `FROM LATITUDE`, `FROM LONGITUDE` and `FROM LOCATION`. These few rows (four to ten rows) can be deleted without a significant impact on the general dataset.\n",
    "\n",
    "A larger portion of missing values can be seen for the columns `GENDER` and `BIRTH YEAR`. Here, a larger amount of rows, roughly 12,000 to 13,000 rows, are missing. One possible solution for dealing with the missing values is by **imputation**. In this case, it has been suggested to analyze the ratio of male to female bike riders and distribute the rows with missing genders accordingly. But due to the size of missing values we, as a group, have decided to delete them instead, in order to keep the integrity of the dataset as well as the correlation to other features. \n",
    "\n",
    "Despite the deletion of those rows, the data still contains sufficient observations with over 100,000 rows which fulfills the given minimum observation requirement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a36162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deletion of rows with null values\n",
    "bike_clean_1 = bike_set.dropna()\n",
    "bike_clean_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54254576",
   "metadata": {},
   "source": [
    "# Feature Selection (column-wise deletion)\n",
    "\n",
    "**Correlation criteria**: \n",
    "\n",
    "- One can observe that `FROM LONGITUDE` and `FROM LATITUDE` are highly correlated to `FROM LOCATION`, which results in redundant information. This also applies to the features `TO LONGITUDE`, `TO LATITUDE` and `TO LOCATION`.\n",
    "- Also, `FROM STATION ID` and `FROM STATION NAME` as well as `TO STATION ID` and `TO STATION NAME` are highly correlated. Therefore, only one feature of each category is needed.\n",
    "- `START TIME` in combination with `STOP TIME` provides the similar information value as `TRIP DURATION`. One can extract the duration with these features. Since trip duration is the core of our model and including `STOP TIME` will result in a data leakage, the stop time will be removed. \n",
    "\n",
    "---\n",
    "\n",
    "- The `TRIP ID` does not offer much explanatory power and does not contribute to the predictability of the target feature `TRIP DURATION`. This feature is relevant for uniquely identifying rows while analyzing and processing the data, but not for training the model itself. Hence, this feature will be removed for the cleaned dataset. \n",
    "- `TO STATION ID` and `TO STATION NAME` will also be removed from the cleaned dataset since the destination of the trip is not given at the start but rather up to the user. The feature therefore has no use in predicting trip durations. This reasoning also applies to `TO LATITUDE`, `TO LONGITUDE` and `TO LOCATION`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of birth year\n",
    "birth_year_counter = bike_clean_1[\"BIRTH YEAR\"].astype(int).value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize = (8,8))\n",
    "plt.bar(birth_year_counter.index, birth_year_counter.values)\n",
    "\n",
    "plt.xlabel(\"birth year\")\n",
    "plt.ylabel(\"user count\")\n",
    "plt.title(\"bike-rider by users' birth year\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78947a41",
   "metadata": {},
   "source": [
    "---\n",
    "Anomalies in `birth year`   \n",
    "As one can observe, there are a few outliers in the year 1900 and 1920. It is highly unlikey that a user is older than 105 years and furthermore, the likelihood of a user of that age to ride a bike is even smaller. That is the reason, why these anomalies will be disregarded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408dd3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove anomalies in bike data, all rows with birth year before 1940\n",
    "bike_clean_1 = bike_clean_1[bike_clean_1[\"BIRTH YEAR\"] >= 1940]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786c681d",
   "metadata": {},
   "source": [
    "# Birth year to age conversion \n",
    "\n",
    "Since age is a more general and intuitive feature than birth year, it should be converted. We do this by subtracting 2019 (year of the data set) by `BIRTH YEAR`, afterwards, this column can be safely removed since we have extracted all the necessary information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823f8ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting birth year to age\n",
    "bike_clean_1[\"AGE\"] = (2019-bike_clean_1[\"BIRTH YEAR\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d54488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of age after clean up\n",
    "age_counter = bike_clean_1[\"AGE\"].astype(int).value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.bar(age_counter.index, age_counter.values)\n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"user count\")\n",
    "plt.title(\"bike-rider by users' age\")\n",
    "# plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec80d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_clean = bike_clean_1.drop(['TRIP ID', 'STOP TIME','FROM STATION NAME','TO STATION ID',\n",
    "                               'TO STATION NAME','FROM LONGITUDE','FROM LATITUDE','TO LATITUDE',\n",
    "                               'TO LONGITUDE','TO LOCATION','BIRTH YEAR'], axis=1)\n",
    "bike_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacbac6f",
   "metadata": {},
   "source": [
    "# Data Engineering Ideas and Progress\n",
    "\n",
    "Features to **KEEP**:\n",
    "+ `START TIME`: Has a high variance and provides much explanatory power - **DONE** \n",
    "+ `BIKE ID`: Keep for now. While individual bike IDs might not seem predictive, they could capture effects of bike age, maintenance, or type if certain ID ranges correspond to different bike characteristics (though such details are not included in the dataset, further considerations needed)\n",
    "+ `FROM STATION ID`: Crucial, Trip duration is heavily dependent on its origin. - **DONE** \n",
    "+ `USER TYPE`: Important. Subscribers and casual customers often exhibit different usage patterns. - **DONE** \n",
    "+ `GENDER`: Potentially useful demographic information. - **DONE** \n",
    "\n",
    "Features to **REMOVE**:\n",
    "+ `TRIP ID`: This is a unique identifier for each row and generally holds no predictive power for the duration of other trips. - **DONE** \n",
    "+ `STOP TIME`: Using this directly would be a data leak, as it inherently defines the trip duration when combined with START TIME - **DONE** \n",
    "+ `FROM LONGITUDE`, `FROM LATITUDE`: Direct corellation to `STATION ID`, since Divvy bikes can only be picked up/ returned on authorised stations, it is sufficient to then only include `STATION ID`. - **DONE**  (However these features might be important for geographical/ demographic data expansion, this point could be revised in the future if needed)\n",
    "+ `TO STATION ID`, `TO LATTITUDE`, `TO LONGTITUDE`: After further research on Divvy services, it seeems the user merely pays for the time frame and not for the distance, since the app won't ask for a destination beforehand (like Uber), therefore the destination cannot be used to predict the duration - **DONE** \n",
    "+ `FROM STATION NAME` and `TO STATION NAME`: These are likely redundant if FROM STATION ID and TO STATION ID are clean and used - **DONE**  \n",
    "+ `FROM LOCATION` and `TO LOCATION`: These appear to be string representations of the latitude/longitude point data. - **DONE** \n",
    "\n",
    "Features to **ADD**:\n",
    "+ Temporal Features (from START TIME):\n",
    "    + HourOfDay\n",
    "    + DayOfWeek\n",
    "    + PartOfDay: Categorical feature (e.g., morning, afternoon, evening, night) based on HourOfDay.\n",
    "+ AGE, calculated from BIRTH YEAR - **DONE** \n",
    "+ Weather Data:\n",
    "    + Temperature\n",
    "    + WindSpeed\n",
    "    + Precipitation\n",
    "+ Location-based Features:\n",
    "    + ZoningDesignation (e.g. residential, business)\n",
    "    + IncomeLevel\n",
    "    + Other interesting demographic details (if found)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
