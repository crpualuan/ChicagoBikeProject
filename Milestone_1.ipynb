{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73eaf1dd",
   "metadata": {},
   "source": [
    "# Milestone 1 - Chicago, U.S. bikesharing\n",
    "\n",
    "`Source`: \n",
    "https://data.cityofchicago.org/Transportation/Divvy-Trips/fg6s-gzvg/about_data \n",
    "\n",
    "`Mobility domain`:\n",
    "https://data.cityofchicago.org/\n",
    "\n",
    "`Github repository`:\n",
    "https://github.com/kbui-03/ChicagoBikeProject\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf681f4",
   "metadata": {},
   "source": [
    "# Target feature of the model: `trip duration` \n",
    "\n",
    "By predicting the duration of each trip, we can:\n",
    "+ Optimise the charging times of electric bikes\n",
    "+ Present customers with a cost estimate\n",
    "+ Reduce bike shortages in rush hour\n",
    "+ and others benefits. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e291c3c7",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "Since the dataset given has a total of roughly **21 million rows**, we need to reduce the size of the data before downloading. In order to do that, we used the provided query function to filter the rows: \n",
    "\n",
    "`TRIP_ID` is greater than or equal to 22,000,000 AND\n",
    "\n",
    "`TRIP_ID` is less than or equal to 22,200,000\n",
    "\n",
    "This left us with about roughly 170.000 unique bike rides to work with, in the time frame of March 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "654bedf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 169540 entries, 0 to 169539\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   TRIP ID            169540 non-null  int64  \n",
      " 1   START TIME         169540 non-null  object \n",
      " 2   STOP TIME          169540 non-null  object \n",
      " 3   BIKE ID            169540 non-null  int64  \n",
      " 4   TRIP DURATION      169540 non-null  int64  \n",
      " 5   FROM STATION ID    169540 non-null  int64  \n",
      " 6   FROM STATION NAME  169540 non-null  object \n",
      " 7   TO STATION ID      169540 non-null  int64  \n",
      " 8   TO STATION NAME    169540 non-null  object \n",
      " 9   USER TYPE          169540 non-null  object \n",
      " 10  GENDER             156307 non-null  object \n",
      " 11  BIRTH YEAR         157020 non-null  float64\n",
      " 12  FROM LATITUDE      169536 non-null  float64\n",
      " 13  FROM LONGITUDE     169536 non-null  float64\n",
      " 14  FROM LOCATION      169536 non-null  object \n",
      " 15  TO LATITUDE        169530 non-null  float64\n",
      " 16  TO LONGITUDE       169530 non-null  float64\n",
      " 17  TO LOCATION        169530 non-null  object \n",
      "dtypes: float64(5), int64(5), object(8)\n",
      "memory usage: 23.3+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "\n",
    "bike_set = pd.read_csv(\"Divvy_Trips_Chicago.csv\", sep=\",\")\n",
    "bike_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213fc737",
   "metadata": {},
   "source": [
    "\n",
    "We can observe that there are rows missing `TO LATITUDE`, `TO LONGITUDE`, `TO LOCATION`, `FROM LATITUDE`, `FROM LONGITUDE` and `FROM LOCATION`. These few rows (four to ten rows) can be deleted without a significant impact on the general dataset.\n",
    "\n",
    "A larger portion of missing values can be seen for the columns `GENDER` and `BIRTH YEAR`. Here, a larger amount of rows, roughly 12,000 to 13,000 rows, are missing. One solution that has been suggested is to analyze the ratio of male to female bike riders and distribute the rows with missing genders accordingly. But due to the size of missing values we, as a group, have decided to delete them instead in order to keep the integrity of the data set as well as the correlation to other features. \n",
    "\n",
    "Despite the deletion of those rows, the data still contains sufficient observations with over 100,000 rows which fulfills the given minimum observation requirement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46a36162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 156296 entries, 0 to 169539\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   TRIP ID            156296 non-null  int64  \n",
      " 1   START TIME         156296 non-null  object \n",
      " 2   STOP TIME          156296 non-null  object \n",
      " 3   BIKE ID            156296 non-null  int64  \n",
      " 4   TRIP DURATION      156296 non-null  int64  \n",
      " 5   FROM STATION ID    156296 non-null  int64  \n",
      " 6   FROM STATION NAME  156296 non-null  object \n",
      " 7   TO STATION ID      156296 non-null  int64  \n",
      " 8   TO STATION NAME    156296 non-null  object \n",
      " 9   USER TYPE          156296 non-null  object \n",
      " 10  GENDER             156296 non-null  object \n",
      " 11  BIRTH YEAR         156296 non-null  float64\n",
      " 12  FROM LATITUDE      156296 non-null  float64\n",
      " 13  FROM LONGITUDE     156296 non-null  float64\n",
      " 14  FROM LOCATION      156296 non-null  object \n",
      " 15  TO LATITUDE        156296 non-null  float64\n",
      " 16  TO LONGITUDE       156296 non-null  float64\n",
      " 17  TO LOCATION        156296 non-null  object \n",
      "dtypes: float64(5), int64(5), object(8)\n",
      "memory usage: 22.7+ MB\n"
     ]
    }
   ],
   "source": [
    "bike_clean = bike_set.dropna()\n",
    "bike_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacbac6f",
   "metadata": {},
   "source": [
    "# Data Engineering Ideas\n",
    "\n",
    "Features to **KEEP**:\n",
    "+ START TIME: Essential\n",
    "+ BIKE ID: Keep for now. While individual bike IDs might not seem predictive, they could capture effects of bike age, maintenance, or type if certain ID ranges correspond to different bike characteristics (though such details are not included in the dataset, further considerations needed)\n",
    "+ FROM STATION ID: Crucial, Trip duration is heavily dependent on its origin.\n",
    "+ USER TYPE: Important. Subscribers and casual customers often exhibit different usage patterns.\n",
    "+ GENDER: Potentially useful demographic information.\n",
    "+ BIRTH YEAR: Useful for deriving rider age.\n",
    "+ FROM LATITUDE, FROM LONGITUDE: Maybe. Since Divvy bikes can only be used to and from authorised stations, it is unclear whether specific coordinates are needed\n",
    "\n",
    "Features to **REMOVE**:\n",
    "+ TRIP ID: This is a unique identifier for each row and generally holds no predictive power for the duration of other trips.\n",
    "+ STOP TIME: Using this directly would be a data leak, as it inherently defines the trip duration when combined with START TIME\n",
    "+ TO STATION ID, TO LATTITUDE, TO LONGTITUDE: After further research on Divvy services, it seeems the user merely pays for the time frame and not for the distance, since the app won't ask for a destination beforehand (like Uber), therefore the destination cannot be used to predict the duration \n",
    "+ FROM STATION NAME and TO STATION NAME: These are likely redundant if FROM STATION ID and TO STATION ID are clean and used\n",
    "+ FROM LOCATION and TO LOCATION: These appear to be string representations of the latitude/longitude point data. \n",
    "\n",
    "Features to **ADD**:\n",
    "+ Temporal Features (from START TIME):\n",
    "    + HourOfDay\n",
    "    + DayOfWeek\n",
    "    + PartOfDay: Categorical feature (e.g., morning, afternoon, evening, night) based on HourOfDay.\n",
    "+ AGE, calculated from BIRTH YEAR\n",
    "+ Weather Data:\n",
    "    + Temperature\n",
    "    + WindSpeed\n",
    "    + Precipitation\n",
    "+ Location-based Features:\n",
    "    + ZoningDesignation (e.g. residential, business)\n",
    "    + IncomeLevel\n",
    "    + Other interesting demographic details (if found)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20defdb5",
   "metadata": {},
   "source": [
    "Todo list:\n",
    "- Handle null values\n",
    "- Decide which features are important\n",
    "- Decide python environment\n",
    "- Decide which new columns to add\n",
    "- Choose appropriate visualisation of the cleaned dataset\n",
    "- Seperate dataset into traning, validation and test data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
